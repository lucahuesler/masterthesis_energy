---
title: "04-Results-step-2"
editor: visual
---

```{r}
#| label: load-libs
#| include: false

library(tidyverse)
library(tidymodels)
library(doParallel)
library(skimr)
library(plotly)
library(sf)
library(agua)
library(gt)
library(rules)
library(baguette)
library(ggridges)
library(viridis)
library(hrbrthemes)
library(finetune)
library(ggrepel)
library(vip)
library(shapviz)
library(DALEXtra)
```

```{r}
#| label: load-data
#| include: false

energy_modelling <- read_rds("data/energy_modelling.rds")
```

## Training on subsets

As outlined in @sec-methodology, the second step of the modelling process consists on training the best model on different data subsets. XGboost provided the best results in step one. Accordingly, we used XGboost for training the model on different subsets of data. In a first step, we splitted the data into single-family houses and mulit-familiy houses and trained a model for each category. Subsequently, we also trained models for each municipality.

### Differnetiating by building class

```{r}
#| label: split-building-class
#| include: false

energy_single_family <- energy_modelling |>
  dplyr::filter(building_class == 1110)

energy_multi_family <- energy_modelling |>
  dplyr::filter(building_class != 1110)

nrow(energy_single_family)
nrow(energy_multi_family)
```

#### Single-family houses

```{r}
#| label: train-test-split-single-family
#| include: false

#> Set the random number stream using `set.seed()` so that the results can be 
#> reproduced later. 
set.seed(502)

#> Save the split information for an 80/20 split of the data
energy_split_single_family <- initial_split(energy_single_family, 
                              prop = 0.8, 
                              strata = hec)
energy_split_single_family


#> Creating train and test set
energy_train_single_family <- training(energy_split_single_family)
energy_test_single_family  <-  testing(energy_split_single_family)

#> defining folds for training sets
set.seed(234)
energy_folds_single_family <- vfold_cv(energy_train_single_family, v = 5, strata = hec)

```

#### Multi-family houses

```{r}
#| label: train-test-split-single-family-mfh
#| include: false

#> Set the random number stream using `set.seed()` so that the results can be 
#> reproduced later. 
set.seed(502)

#> Save the split information for an 80/20 split of the data
energy_split_multi_family <- initial_split(energy_multi_family, 
                              prop = 0.8, 
                              strata = hec)
energy_split_multi_family


#> Creating train and test set
energy_train_multi_family <- training(energy_split_multi_family)
energy_test_multi_family  <-  testing(energy_split_multi_family)

#> defining folds for training sets
set.seed(234)
energy_folds_multi_family <- vfold_cv(energy_train_multi_family, v = 5, strata = hec)

```

```{r}
#| label: preprocessing-base-recipe-hec
#| include: false

# Specify basic recipe (applicable to all models)
recipe_base_hec_building_class <- recipe(hec ~ .,
                          data = energy_train_single_family) |> 
   step_select(egid, 
         hepi, 
         hec, 
         survey_year, 
         num_residents, 
         num_floors, 
         building_area_m2, 
         gross_floor_area_m2, 
         heated_area_m2, 
         year_of_installation, 
         efficiency_of_installation, 
         energy_usage_of_installation, 
         solar_system, 
         solar_system_area_m2, 
         solar_system_usage, 
         solar_system_area_m2, 
         photovoltaic_system, 
         photovoltaic_system_power_kw, 
         municipality_code, 
         building_class, 
         construction_year, 
         coordinate_e, 
         coordinate_n, 
         num_dwellings, 
         meters_above_sealevel, 
         energy_production_solar_mwh, 
         energy_consumed_hot_water_mwh,
         retrofitted,
         retrofit_investment_costs,
         hdd,
         hepi_pred_current_method,
         hec_pred_current_method) |>
  # remove variables from predictors that are only used for info or later comparison 
  update_role(egid, hepi, hepi_pred_current_method, hec_pred_current_method, new_role = "id") |>
  # Create dummy variables for nominal predictors
  step_dummy(all_nominal()) |>
  # Remove variables that contain only one value
  step_zv(all_numeric_predictors()) |>
  # Impute means for variables with NA
  step_impute_mean(num_residents) |>
  step_impute_mean(year_of_installation)

recipe_base_hec_building_class
```

```{r}
#| label: xgboost-workflow
#| include: false

#> xgb with the tuning results of the grid search in step 1
xgboost_spec <- 
   boost_tree(trees = 1000,
              min_n = 7,
              tree_depth = 7,
              learn_rate = 0.09,
              loss_reduction = 0.000699,
              sample_size = 0.824) %>% 
   set_engine("xgboost") %>% 
   set_mode("regression")


xgb_workflow <- workflow(recipe_base_hec_building_class, xgboost_spec)
```

```{r}
#| include: false

xgb_fit_single_family <- xgb_workflow %>% 
  last_fit(split = energy_split_single_family)

xgb_fit_multi_family <- xgb_workflow %>% 
  last_fit(split = energy_split_multi_family)
```

```{r}
single_family_metrics <- xgb_fit_single_family |>
  collect_metrics()

multi_family_metrics <- xgb_fit_multi_family |>
  collect_metrics()

building_class_metrics <- single_family_metrics |>
  bind_rows(multi_family_metrics)

building_class_metrics
```

```{r}
xgb_fit_single_family %>% 
   collect_predictions() %>% 
   ggplot(aes(x = hec, y = .pred)) + 
   geom_abline(color = "gray50", lty = 2) + 
   geom_point(alpha = 0.5) + 
   coord_obs_pred() + 
   labs(x = "observed", y = "predicted")

xgb_fit_multi_family %>% 
   collect_predictions() %>% 
   ggplot(aes(x = hec, y = .pred)) + 
   geom_abline(color = "gray50", lty = 2) + 
   geom_point(alpha = 0.5) + 
   coord_obs_pred() + 
   labs(x = "observed", y = "predicted")
```

```{r}
#| label: metrics-current-approach
#| include: false

energy_train_current_method_single_family <- energy_train_single_family |>
  dplyr::inner_join(energy_modelling, by = c("egid", "survey_year"), suffix = c("", "_y")) |>
  dplyr::select(egid, survey_year, hec, hepi, hepi_pred_current_method, hec_pred_current_method, heated_area_m2)

custom_metrics <- metric_set(rmse, mape, mae, rsq)

energy_train_metrics_single_family_current_method <- energy_train_current_method |>
  custom_metrics(hec, hec_pred_current_method)

energy_train_metrics_current_method


energy_modelling |>
  filter(egid == 390049) |>
  select(egid, survey_year, hec, hec_pred_current_method, hepi, hepi_pred_current_method)
```

```{r}
#| label: xgboost-tuning
#| include: false

set.seed(123)
xgb_grid <-
  grid_max_entropy(
    tree_depth(c(5L, 10L)),
    min_n(c(10L, 40L)),
    mtry(c(5L, 10L)),
    sample_prop(c(0.5, 1.0)),
    learn_rate(c(-2, -1)),
    size = 20
  )

xgb_grid


```

```{r}
#| label: xgboost-tune-racing
#| include: false
#| eval: false
doParallel::registerDoParallel()

set.seed(234)
xgb_racing <-
  tune_race_anova(
    xgb_workflow,
    energy_folds_single_family,
    grid = xgb_grid,
    #metrics = metric_set(mn_log_loss),
    control = control_race(verbose_elim = TRUE)
  )

xgb_racing
```

#### Feature importance

```{r}
#| label: feature-importance-vip
#| include: false

vip_features <- c("heated_area_m2", "meters_above_sealevel", "construction_year", 
                  "coordinate_n", "coordinate_e", "solar_system")

vip_train <- 
  energy_train_single_family 


xgb_fit_workflow <- xgb_fit_single_family |>
  extract_workflow()

explainer_xgboost <- 
  explain_tidymodels(
    xgb_fit_workflow, 
    data = vip_train, 
    y = energy_train_single_family$hec,
    label = "XGboost",
    verbose = FALSE
  )

explainer_xgboost
```

Explain model for a single observation

```{r}
efh <- vip_train[120,]
efh
```

```{r}

xgboost_breakdown <- predict_parts(explainer = explainer_xgboost, new_observation = efh)

xgboost_breakdown
```

```{r}
#| label: feature-importance-shap
#| include: false

shap <- test_results |>
   extract_fit_engine() |>
   shapviz()

sv_importance(shap, kind = "both", show_numbers = TRUE)
sv_dependence(shap, "carat", color_var = "auto")
sv_dependence(shap, "clarity", color_var = "auto")
sv_force(shap, row_id = 1)
sv_waterfall(shap, row_id = 1)
```
